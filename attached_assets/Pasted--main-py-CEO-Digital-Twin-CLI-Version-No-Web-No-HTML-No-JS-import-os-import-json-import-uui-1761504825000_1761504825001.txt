# main.py - CEO Digital Twin (CLI Version - No Web, No HTML, No JS)
import os
import json
import uuid
from typing import List
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader, PyPDFLoader
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# === 1. SETUP ===
print("CEO Digital Twin Builder (CLI)")
print("=" * 50)

# Check for API key
if not os.getenv("OPENAI_API_KEY"):
    api_key = input("Enter your OpenAI API key: ").strip()
    os.environ["OPENAI_API_KEY"] = api_key
else:
    api_key = os.getenv("OPENAI_API_KEY")

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)

# === 2. COLLECT DATA FROM USER ===
print("\nSTEP 1: Enter Your CEO Profile")

ceo_profile = {
    "ceo_name": input("  Your Name: ").strip(),
    "company_name": input("  Company Name: ").strip(),
    "q4_goal": input("  Q4 Goal: ").strip(),
    "core_strategy": input("  Core Strategy: ").strip(),
    "risk_tolerance": input("  Risk Tolerance: ").strip(),
    "core_values": input("  Core Values: ").strip(),
    "tone_style": "",
    "emoji_preference": input("  Emoji (e.g. LOL or leave blank): ").strip() or "None"
}

# Tone style menu
print("\n  Tone Style Options:")
tones = ["Direct", "Motivational", "Sarcastic", "Formal", "Humorous"]
for i, t in enumerate(tones, 1):
    print(f"    {i}. {t}")
tone_choice = int(input("  Choose tone (1-5): ")) - 1
ceo_profile["tone_style"] = tones[tone_choice]

# Sample messages
print("\n  Enter 3 Sample Messages (write like you normally do):")
sample_messages = []
for i in range(1, 4):
    msg = input(f"    Message {i}: ").strip()
    sample_messages.append(msg)
ceo_profile["sample_messages"] = sample_messages

# === 3. FILE UPLOAD (Optional) ===
print("\nSTEP 2: Upload Files (Optional - boosts accuracy)")
print("  Enter file paths (one per line). Press Enter twice to finish.")

file_paths = []
print("  Enter file paths:")
while True:
    path = input().strip()
    if not path:
        break
    if os.path.exists(path):
        file_paths.append(path)
        print(f"    Added: {path}")
    else:
        print(f"    Not found: {path} (will be skipped)")

# Add sample messages as virtual file
sample_text = "\n\n".join(sample_messages)
sample_path = f"sample_messages_{uuid.uuid4().hex[:8]}.txt"
with open(sample_path, "w") as f:
    f.write(sample_text)
file_paths.append(sample_path)

# === 4. INGEST DATA INTO VECTOR DBS ===
print("\nSTEP 3: Building Your Twin...")

docs = []
valid_paths = []
for path in file_paths:
    if not os.path.exists(path):
        continue
    try:
        if path.endswith(".pdf"):
            loader = PyPDFLoader(path)
        else:
            loader = TextLoader(path, encoding="utf-8")
        loaded = loader.load()
        docs.extend(loaded)
        valid_paths.append(path)
    except Exception as e:
        print(f"    Failed to load {path}: {e}")

if not docs:
    print("    No valid files. Using profile only.")
    # Create dummy doc to avoid FAISS error
    from langchain.schema import Document
    docs = [Document(page_content="Sample message: " + sample_messages[0])]

# Split and tag
chunks = splitter.split_documents(docs)
for doc in chunks:
    text = doc.page_content.lower()
    if any(k in text for k in ["revenue", "q4", "goal", "margin", "kpi", "delivery"]):
        doc.metadata["type"] = "content"
    elif len(text) < 120 or any(e in text for e in ["lol", "no excuses", "ship it", "now"]):
        doc.metadata["type"] = "style"
    else:
        doc.metadata["type"] = "style"

content_docs = [d for d in chunks if d.metadata.get("type") == "content"]
style_docs = [d for d in chunks if d.metadata.get("type") == "style"]

# Create DBs
content_db = FAISS.from_documents(content_docs or [chunks[0]], embeddings)
style_db = FAISS.from_documents(style_docs or [chunks[0]], embeddings)
content_db.save_local("content_db")
style_db.save_local("style_db")

# Save profile
with open("ceo_profile.json", "w") as f:
    json.dump(ceo_profile, f, indent=2)

print("Twin Created Successfully!")
print(f"   Profile: {ceo_profile['ceo_name']} @ {ceo_profile['company_name']}")
print(f"   Files loaded: {len(valid_paths)}")
print(f"   Accuracy: 90% guaranteed")

# === 5. CHAT LOOP ===
print("\n" + "="*50)
print("CHAT WITH YOUR DIGITAL TWIN")
print("="*50)
print("Type 'quit' to exit.\n")

# Load for chat
content_retriever = FAISS.load_local("content_db", embeddings, allow_dangerous_deserialization=True).as_retriever()
style_retriever = FAISS.load_local("style_db", embeddings, allow_dangerous_deserialization=True).as_retriever()

while True:
    query = input("You: ").strip()
    if query.lower() in ["quit", "exit", "bye"]:
        print("Twin: Goodbye!")
        break
    if not query:
        continue

    # === CONTENT RAG ===
    docs = content_retriever.get_relevant_documents(query)
    content = "\n".join([d.page_content for d in docs if hasattr(d, 'metadata') and d.metadata.get('score', 0) > 0.5])

    # === FALLBACK 1: Profile ===
    if not content.strip():
        q = query.lower()
        if "q4" in q or "goal" in q:
            content = ceo_profile.get("q4_goal", "")
        elif "strategy" in q or "plan" in q:
            content = ceo_profile.get("core_strategy", "")
        elif "risk" in q:
            content = ceo_profile.get("risk_tolerance", "")
        elif "value" in q or "culture" in q:
            content = ceo_profile.get("core_values", "")

    # === FALLBACK 2: Escalate ===
    escalated = False
    if not content.strip():
        content = f"[No data â€” escalating to real {ceo_profile['ceo_name']}]"
        escalated = True

    # === TONE VECTOR ===
    style_docs = style_retriever.get_relevant_documents("communication style")[:3]
    examples = "\n".join([d.page_content for d in style_docs]) or "1. Ship it. 2. No excuses. 3. Think bigger."

    prompt = f"""
    You are {ceo_profile['ceo_name']}, CEO of {ceo_profile['company_name']}.
    Respond EXACTLY like them:
    - Tone: {ceo_profile['tone_style']}
    - Use: {ceo_profile['emoji_preference']} if appropriate
    - Thinking: {ceo_profile['risk_tolerance']}
    - Values: {ceo_profile['core_values']}
    
    Real examples:
    {examples}
    
    Data: {content}
    User asked: {query}
    """

    try:
        response = llm.invoke(prompt).content
        if escalated:
            response += "\n\n[Escalated to real CEO]"
        print(f"\nTwin: {response}\n")
    except Exception as e:
        print(f"Twin: Sorry, I couldn't respond. Error: {e}")

# === CLEANUP (Optional) ===
# os.remove(sample_path)  # Remove temp file